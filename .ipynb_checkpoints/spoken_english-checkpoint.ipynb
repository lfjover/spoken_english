{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "#from collections import Counter\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 9.21\\tLENORE: \\t... So you don't need to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.21 9.52\\t        \\tto --</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.52 14.10\\t        \\t... to do the feet?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.10 15.78\\t        \\t... [Do the hooves]?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01 16.78\\tLYNNE:  \\t    [(H)=] &lt;YWN Well</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1\n",
       "0  0.00 9.21\\tLENORE: \\t... So you don't need to ...  NaN\n",
       "1                         9.21 9.52\\t        \\tto --  NaN\n",
       "2          9.52 14.10\\t        \\t... to do the feet?  NaN\n",
       "3        14.10 15.78\\t        \\t... [Do the hooves]?  NaN\n",
       "4        15.01 16.78\\tLYNNE:  \\t    [(H)=] <YWN Well  NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = pd.read_csv('data/transcripts/SBC001.trn',header=None)\n",
    "chat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/transcripts/SBC018.trn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.250\\t1.045\\tMARCIA:\\tThey might not actually be,',\n",
       " '1.045\\t1.335\\t\\t... be um,',\n",
       " '1.335\\t2.290\\t\\t... back in the barn- --',\n",
       " '1.540\\t3.000\\t\\t<X or [from X> the barn yet].',\n",
       " '2.325\\t2.715\\tLINDSEY:\\t      [(TSK) Good morning,']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data/transcripts/SBC018.trn'\n",
    "print file_path\n",
    "chat = []\n",
    "with open(file_path) as f:\n",
    "    for line in f:\n",
    "        chat.append(line.strip())\n",
    "chat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/transcripts/SBC014.trn\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/transcripts/SBC014.trn'\n",
    "print file_path\n",
    "chat = []\n",
    "with open(file_path) as f:\n",
    "    for line in f:        \n",
    "        current_line = line.strip().split('\\t')\n",
    "        current_line[0] = current_line[0].split(' ')\n",
    "        current_line[0]= '\\t'.join(current_line[0][:3])\n",
    "        current_line = '\\t'.join(current_line)\n",
    "        chat.append(current_line+'\\n')\n",
    "\n",
    "file_path = 'data/transcripts/prueba.trn'\n",
    "with open(file_path,'w') as f:\n",
    "    for line in chat:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path[21:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_chat(file_path):\n",
    "    #print file_path\n",
    "    chat = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            chat.append(line.strip().split('\\t'))\n",
    "\n",
    "    if int(file_path[21:23])<14:\n",
    "        chat[:] = [line for line in chat if len(line)==3] #delete comments\n",
    "        # separate end and start times\n",
    "        for i,line in enumerate(chat):\n",
    "            chat[i] = chat[i][0].split() + line[1:] \n",
    "            m = re.search(':',chat[i][2])\n",
    "            if m:\n",
    "                chat[i][2] = chat[i][2][:m.start()]\n",
    "            else:\n",
    "                chat[i][2] = chat[i-1][2]\n",
    "    else:\n",
    "        chat[:] = [line for line in chat if len(line)==4]\n",
    "    \n",
    "    chat = pd.DataFrame(chat)\n",
    "    chat.columns = ['start_time','end_time','person','speech']\n",
    "    \n",
    "    # clean speech\n",
    "    chat['clean_speech'] = chat.speech #placeholder\n",
    "    for i,text in enumerate(chat.clean_speech):\n",
    "        text = re.sub(r'\\[.*\\]', '', text)\n",
    "        text = re.sub(r'\\(.*\\)', '', text)\n",
    "        text = re.sub(r'=','',text)\n",
    "        text = re.sub(r'[^A-Za-z\\']',' ',text)\n",
    "        chat.clean_speech[i] = text.split()\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_list_of_words(clean_speech_series):\n",
    "    \"\"\"get list of words from time series of clean speech\"\"\"\n",
    "    \n",
    "    words = []\n",
    "    for text in clean_speech_series:\n",
    "        words = words + text\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/transcripts/SBC001.trn\n",
      "data/transcripts/SBC002.trn\n",
      "data/transcripts/SBC003.trn\n",
      "data/transcripts/SBC004.trn\n",
      "data/transcripts/SBC005.trn\n",
      "data/transcripts/SBC006.trn\n",
      "data/transcripts/SBC007.trn\n",
      "data/transcripts/SBC008.trn\n",
      "data/transcripts/SBC009.trn\n",
      "data/transcripts/SBC010.trn\n",
      "data/transcripts/SBC011.trn\n",
      "data/transcripts/SBC012.trn\n",
      "data/transcripts/SBC013.trn\n",
      "data/transcripts/SBC014.trn\n",
      "data/transcripts/SBC015.trn\n",
      "data/transcripts/SBC016.trn\n",
      "data/transcripts/SBC017.trn\n",
      "data/transcripts/SBC018.trn\n",
      "data/transcripts/SBC019.trn\n",
      "data/transcripts/SBC020.trn\n",
      "data/transcripts/SBC021.trn\n",
      "data/transcripts/SBC022.trn\n",
      "data/transcripts/SBC023.trn\n",
      "data/transcripts/SBC024.trn\n",
      "data/transcripts/SBC025.trn\n",
      "data/transcripts/SBC026.trn\n",
      "data/transcripts/SBC027.trn\n",
      "data/transcripts/SBC028.trn\n",
      "data/transcripts/SBC029.trn\n",
      "data/transcripts/SBC030.trn\n",
      "data/transcripts/SBC031.trn\n",
      "data/transcripts/SBC032.trn\n",
      "data/transcripts/SBC033.trn\n",
      "data/transcripts/SBC034.trn\n",
      "data/transcripts/SBC035.trn\n",
      "data/transcripts/SBC036.trn\n",
      "data/transcripts/SBC037.trn\n",
      "data/transcripts/SBC038.trn\n",
      "data/transcripts/SBC039.trn\n",
      "data/transcripts/SBC040.trn\n",
      "data/transcripts/SBC041.trn\n",
      "data/transcripts/SBC042.trn\n",
      "data/transcripts/SBC043.trn\n",
      "data/transcripts/SBC044.trn\n",
      "data/transcripts/SBC045.trn\n",
      "data/transcripts/SBC046.trn\n",
      "data/transcripts/SBC047.trn\n",
      "data/transcripts/SBC048.trn\n",
      "data/transcripts/SBC049.trn\n",
      "data/transcripts/SBC050.trn\n",
      "data/transcripts/SBC051.trn\n",
      "data/transcripts/SBC052.trn\n",
      "data/transcripts/SBC053.trn\n",
      "data/transcripts/SBC054.trn\n",
      "data/transcripts/SBC055.trn\n",
      "data/transcripts/SBC056.trn\n",
      "data/transcripts/SBC057.trn\n",
      "data/transcripts/SBC058.trn\n",
      "data/transcripts/SBC059.trn\n",
      "data/transcripts/SBC060.trn\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary with all the words\n",
    "chat1 = process_chat('data/transcripts/SBC001.trn')\n",
    "words = get_list_of_words(chat1.clean_speech)\n",
    "word_dict = Counter(words)\n",
    "\n",
    "file_names = os.listdir('data/transcripts')\n",
    "for file_name in file_names[1:] :\n",
    "    chat = process_chat('data/transcripts/'+file_name)\n",
    "    word_dict.update(get_list_of_words(chat.clean_speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
